{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp label_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def classify_unlabeled_texts(df, text_column, label_column):\n",
    "    # Filter to get labeled examples for the prompt\n",
    "    labeled_examples = df[df[label_column].notna()]\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    # Iterate over rows that need classification\n",
    "    for index, row in df[df[label_column].isna()].iterrows():\n",
    "        messages = [{\"role\": \"system\", \"content\": \"The following are examples of texts and their classifications, the label is either 'OTR', 'PRS', 'REP', or 'NEU'. 'OTR' stands for 'An opportunity to respond' (e.g., 'What color is this candy?'), 'PRS' stands for 'Praise' (e.g., 'Great job, Morgan!'), 'REP' stands for 'Reprimand' (e.g., 'You need to keep quiet while someone else is reading.) and 'NEU' stands for 'None of the above':\"}]\n",
    "        \n",
    "        # Add few-shot learning examples\n",
    "        for _, example_row in labeled_examples.iterrows():\n",
    "            example = f\"Text: {example_row[text_column]}\\nLabel: {example_row[label_column]}\"\n",
    "            messages.append({\"role\": \"user\", \"content\": example})\n",
    "\n",
    "        # Add the text to be classified\n",
    "        text_to_classify = row[text_column]\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Text: {text_to_classify}\\nLabel:\"})\n",
    "\n",
    "        # Make the request to OpenAI's chat API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        # Update the DataFrame with the classified label\n",
    "        classified_label = response.choices[0].message['content'].strip()\n",
    "        df.at[index, label_column] = classified_label\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def start_to_label(uploaded_file, chunk_size, text_column=\"Text\", label_column=\"Label\"):\n",
    "    df = pd.read_csv(uploaded_file.name, encoding='utf-8')\n",
    "    df = df[[text_column, label_column]]\n",
    "    return df.head(int(chunk_size)), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def correct_dataframe(dataframe_display, file_input, current_dataframe, accuracy_log, chunk_size, chunk_count, text_column = \"Text\", label_column=\"Label\"):\n",
    "    max_chunk_count = len(current_dataframe) / chunk_size if len(current_dataframe) % chunk_size == 0 else int(len(current_dataframe) / chunk_size) + 1\n",
    "    \n",
    "    \n",
    "    temp_df = current_dataframe.copy()\n",
    "\n",
    "\n",
    "    # only iterate through the rows that are not empty\n",
    "    \n",
    "    for _, row in dataframe_display[~dataframe_display[label_column].isna()].iterrows():\n",
    "        # current_dataframe[current_dataframe[text_column] == row[text_column]][label_column] = row[label_column]\n",
    "\n",
    "        # use .loc[row_indexer,col_indexer] = value instead\n",
    "        current_dataframe.loc[current_dataframe[text_column] == row[text_column], label_column] = row[label_column]\n",
    "\n",
    "    # Check if \"_AI_assisted.csv\" is in the name of file_output\n",
    "    accuracy = None\n",
    "\n",
    "    if chunk_count > 1:\n",
    "        compared_chunk_temp = temp_df.loc[min(chunk_size * (chunk_count - 1), len(temp_df) - chunk_size): min(chunk_size * chunk_count - 1, len(temp_df) - 1)]\n",
    "        compared_chunk_current = current_dataframe.loc[min(chunk_size * (chunk_count - 1), len(current_dataframe) - chunk_size): min(chunk_size * chunk_count - 1, len(current_dataframe) - 1)]\n",
    "        # Calculate the accuracy based on how many rows of the dataframe_display is different from the current_dataframe\n",
    "        merged_df = pd.merge(compared_chunk_temp, compared_chunk_current, on=text_column, suffixes=('_before', '_current'))\n",
    "        merged_df.dropna(subset=[f'{label_column}_current', f'{label_column}_before'], inplace=True)\n",
    "\n",
    "        # with open('merged_df.csv', 'w') as f:\n",
    "        #     f.write(merged_df.to_csv(merged_df[f'{label_column}_before'] != merged_df[f'{label_column}_current']).sum())\n",
    "        accuracy = 1 - (merged_df[f'{label_column}_before'] != merged_df[f'{label_column}_current']).sum() / len(merged_df)\n",
    "        if len(accuracy_log) < max_chunk_count - 1:\n",
    "            accuracy_log.append(accuracy)\n",
    "\n",
    "    if accuracy != 1:\n",
    "        current_dataframe.loc[min(chunk_size * chunk_count, len(current_dataframe) - chunk_size): , label_column] = None\n",
    "        current_dataframe = classify_unlabeled_texts(current_dataframe, 'Text', 'Label')\n",
    "\n",
    "    new_file = file_input.name.split('.')[0] + '_AI_assisted.csv'\n",
    "\n",
    "    current_dataframe.to_csv(new_file)\n",
    "\n",
    "    dataframe_display = current_dataframe.loc[min(chunk_size * chunk_count, len(current_dataframe) - chunk_size): min(chunk_size*(chunk_count+1)-1, len(current_dataframe) - 1)]\n",
    "\n",
    "    if chunk_count < max_chunk_count - 1:\n",
    "        chunk_count += 1\n",
    "\n",
    "    return dataframe_display, new_file, current_dataframe, accuracy_log, chunk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_plot(accuracy_log, save_path=\"plot.png\"):\n",
    "    ax = plt.figure()\n",
    "    # X is the index of the accuracy_log, y is the value in accuray_log\n",
    "    plt.plot(range(len(accuracy_log)), accuracy_log)\n",
    "    plt.xlabel('Batch Index')\n",
    "    plt.ylabel('Batch Accuracy')\n",
    "    plt.title('Batch Accuracy over time')\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    # buf = io.BytesIO()\n",
    "    plt.savefig(save_path, format='png')\n",
    "    # buf.seek(0)\n",
    "\n",
    "    # Return the plot and the file for download\n",
    "    return ax, save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key_dict = json.load(open('../api_key.json', 'r'))\n",
    "# for key in key_dict:\n",
    "#     os.environ[key] = key_dict[key]\n",
    "\n",
    "# df = pd.read_csv('../data/009-1.csv')\n",
    "# response = classify_unlabeled_texts(df, 'Text', 'Label')\n",
    "# print(response)\n",
    "# print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(response['Label'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
