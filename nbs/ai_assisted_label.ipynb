{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ai_ass_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply color based on confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def apply_color(val):\n",
    "    # Set color corresponding to the confidence score\n",
    "    if float(val) > 0.7:\n",
    "        color = 'green'\n",
    "    elif float(val) < 0.3:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = \"yellow\"\n",
    "\n",
    "    return f'background-color: {color}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classified unlabeled texts one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def classify_unlabeled_texts(df, text_column, label_column):\n",
    "    # Filter to get labeled examples for the prompt\n",
    "    labeled_examples = df[df[label_column].notna()]\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    # Iterate over rows that need classification\n",
    "    for index, row in df[df[label_column].isna()].iterrows():\n",
    "        messages = [{\"role\": \"system\", \"content\": \"The following are examples of texts and their classifications, the label is either 'OTR', 'PRS', 'REP', or 'NEU'. 'OTR' stands for 'An opportunity to respond' (e.g., 'What color is this candy?'), 'PRS' stands for 'Praise' (e.g., 'Great job, Morgan!'), 'REP' stands for 'Reprimand' (e.g., 'You need to keep quiet while someone else is reading.) and 'NEU' stands for 'None of the above':\"}]\n",
    "        \n",
    "        # Add few-shot learning examples\n",
    "        for _, example_row in labeled_examples.iterrows():\n",
    "            example = f\"Text: {example_row[text_column]}\\nLabel: {example_row[label_column]}\"\n",
    "            messages.append({\"role\": \"user\", \"content\": example})\n",
    "\n",
    "        # Add the text to be classified\n",
    "        text_to_classify = row[text_column]\n",
    "        messages.append({\"role\": \"user\", \"content\": f\"Text: {text_to_classify}\\nLabel:\"})\n",
    "\n",
    "        # Make the request to OpenAI's chat API\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        # Update the DataFrame with the classified label\n",
    "        classified_label = response.choices[0].message['content'].strip()\n",
    "        df.at[index, label_column] = classified_label\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classified unlabeled texts at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def classify_unlabeled_texts_all(df, text_column, label_column):\n",
    "    # Filter to get labeled examples for the prompt\n",
    "    labeled_examples = df[df[label_column].notna()]\n",
    "    openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    prompt =  \"You are a Label assistant that could help label unlabeled texts into labels, the following are examples of texts and their corresponding labels, the label is either 'OTR', 'PRS', 'REP', or 'NEU'. 'OTR' stands for 'An opportunity to respond' (e.g., 'What color is this candy?'), 'PRS' stands for 'Praise' (e.g., 'Great job, Morgan!'), 'REP' stands for 'Reprimand' (e.g., 'You need to keep quiet while someone else is reading.) and 'NEU' stands for 'None of the above':\"\n",
    "    \n",
    "    few_shot_examples_texts = \"\"\n",
    "    for _, example_row in labeled_examples.iterrows():\n",
    "        few_shot_examples_texts += f\"Texts:{example_row[text_column]}\\nLabels: {example_row[label_column]}\\n\"\n",
    "\n",
    "    prompt += few_shot_examples_texts\n",
    "    prompt += \"Now Label the following texts:\\n\"\n",
    "\n",
    "    text_to_classify = \"\"\n",
    "\n",
    "    # Iterate over rows that need classification\n",
    "    for index, row in df[df[label_column].isna()].iterrows():\n",
    "        # Add the text to be classified\n",
    "        text_to_classify += f\"Texts: {row[text_column]}\\n\"\n",
    "\n",
    "    prompt += text_to_classify\n",
    "\n",
    "        # Make the request to OpenAI's chat API\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": str(prompt)}]\n",
    "    )\n",
    "    \n",
    "    contents = response.choices[0].message['content'].strip()\n",
    "    # Extract all the labels\n",
    "    # use regex to extract the labels 'OTR', 'PRS', 'REP', or 'NEU' from the response\n",
    "    regex = r\"(OTR|PRS|REP|NEU)\"\n",
    "    classified_labels = re.findall(regex, contents)\n",
    "    # Update the DataFrame with the classified label\n",
    "    \n",
    "    for index, row in df[df[label_column].isna()].iterrows():\n",
    "        try:\n",
    "            df.at[index, label_column] = classified_labels.pop(0)\n",
    "        except:\n",
    "            df.at[index, label_column] = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Assisted labeling (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def ai_assisted_labeling(uploaded_file, label_column = 'Label', text_column='Text'):\n",
    "    # Placeholder for AI Labeling Logic\n",
    "    df = pd.read_csv(uploaded_file.name, encoding='utf-8')\n",
    "\n",
    "    # if label_column not in df.columns, create a new column with the label_column name\n",
    "    if label_column not in df.columns:\n",
    "        df[label_column] = None\n",
    "    df = df[[text_column, label_column]]\n",
    "    # Process the dataframe\n",
    "    # prompt = generate_prompt(df)\n",
    "\n",
    "    # response = inference_by_openai(prompt)\n",
    "\n",
    "    # add random confidence score to each row in confidence column, the confidence score is between 0 and 1\n",
    "    df['Confidence'] = [round(random.random(), 2) for _ in range(len(df))]\n",
    "    \n",
    "    # set confidence as 1 is the label is in a valid list of labels\n",
    "    df.loc[df['Label'].isin(['PRS', 'OTR', 'REP', 'NEU']), 'Confidence'] = 1\n",
    "    \n",
    "    # def apply_color(var):\n",
    "    #     color = 'red' if var is None else 'green'\n",
    "    #     return f'background-color: {color}'\n",
    "\n",
    "    style_df = df.style.applymap(apply_color, subset=['Confidence'])\n",
    "\n",
    "    df = classify_unlabeled_texts_all(df, 'Text', 'Label')\n",
    "\n",
    "    # Save the new dataframe to a CSV file\n",
    "    new_filename = uploaded_file.name.split('.')[0] + '_AI_assisted.csv'\n",
    "    df.to_csv(new_filename, index=False)\n",
    "    \n",
    "\n",
    "    return style_df.to_html(), new_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI Assisted Labeling (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def start_to_label(uploaded_file, chunk_size, accuracy_log, chunk_count, text_column=\"Text\", label_column=\"Label\"):\n",
    "    # initial the accuracy log and chunk count when it is started\n",
    "    accuracy_log = []\n",
    "    chunk_count = 0\n",
    "    df = pd.read_csv(uploaded_file.name, encoding='utf-8')\n",
    "    if label_column not in df.columns:\n",
    "        df[label_column] = None\n",
    "    df = df[[text_column, label_column]]\n",
    "    return df.head(int(chunk_size)), df, accuracy_log, chunk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def correct_dataframe(dataframe_display, file_input, current_dataframe, accuracy_log, chunk_size, chunk_count, text_column = \"Text\", label_column=\"Label\"):\n",
    "    max_chunk_count = len(current_dataframe) / chunk_size if len(current_dataframe) % chunk_size == 0 else int(len(current_dataframe) / chunk_size) + 1\n",
    "    \n",
    "    temp_df = current_dataframe.copy()\n",
    "\n",
    "    # only iterate through the rows that are not empty\n",
    "    \n",
    "    for _, row in dataframe_display[~dataframe_display[label_column].isna()].iterrows():\n",
    "        # current_dataframe[current_dataframe[text_column] == row[text_column]][label_column] = row[label_column]\n",
    "\n",
    "        # use .loc[row_indexer,col_indexer] = value instead\n",
    "        current_dataframe.loc[current_dataframe[text_column] == row[text_column], label_column] = row[label_column]\n",
    "\n",
    "    # Check if \"_AI_assisted.csv\" is in the name of file_output\n",
    "    accuracy = None\n",
    "\n",
    "    if chunk_count > 0:\n",
    "        compared_chunk_temp = temp_df.loc[min(chunk_size * (chunk_count - 1), len(temp_df) - chunk_size): min(chunk_size * chunk_count - 1, len(temp_df) - 1)]\n",
    "        compared_chunk_current = current_dataframe.loc[min(chunk_size * (chunk_count - 1), len(current_dataframe) - chunk_size): min(chunk_size * chunk_count - 1, len(current_dataframe) - 1)]\n",
    "        # Calculate the accuracy based on how many rows of the dataframe_display is different from the current_dataframe\n",
    "        merged_df = pd.merge(compared_chunk_temp, compared_chunk_current, on=text_column, suffixes=('_before', '_current'))\n",
    "        merged_df.dropna(subset=[f'{label_column}_current', f'{label_column}_before'], inplace=True)\n",
    "\n",
    "        # with open('merged_df.csv', 'w') as f:\n",
    "        #     f.write(merged_df.to_csv(merged_df[f'{label_column}_before'] != merged_df[f'{label_column}_current']).sum())\n",
    "        accuracy = 1 - (merged_df[f'{label_column}_before'] != merged_df[f'{label_column}_current']).sum() / len(merged_df)\n",
    "        if len(accuracy_log) < max_chunk_count - 1:\n",
    "            accuracy_log.append(accuracy)\n",
    "\n",
    "    if accuracy != 1:\n",
    "        current_dataframe.loc[min(chunk_size * chunk_count, len(current_dataframe) - chunk_size): , label_column] = None\n",
    "        current_dataframe = classify_unlabeled_texts_all(current_dataframe, 'Text', 'Label')\n",
    "\n",
    "    new_file = file_input.name.split('.')[0] + '_AI_assisted.csv'\n",
    "\n",
    "    current_dataframe.to_csv(new_file)\n",
    "\n",
    "    dataframe_display = current_dataframe.loc[min(chunk_size * chunk_count, len(current_dataframe) - chunk_size): min(chunk_size*(chunk_count+1)-1, len(current_dataframe) - 1)]\n",
    "\n",
    "    if chunk_count < max_chunk_count - 1:\n",
    "        chunk_count += 1\n",
    "\n",
    "    return dataframe_display, new_file, current_dataframe, accuracy_log, chunk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_plot(accuracy_log, save_path=\"plot.png\"):\n",
    "    ax = plt.figure()\n",
    "    # X is the index of the accuracy_log, y is the value in accuray_log\n",
    "    plt.plot(range(len(accuracy_log)), accuracy_log)\n",
    "    plt.xlabel('Batch Index')\n",
    "    plt.ylabel('Batch Accuracy')\n",
    "    plt.title('Batch Accuracy over time')\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    # buf = io.BytesIO()\n",
    "    plt.savefig(save_path, format='png')\n",
    "    # buf.seek(0)\n",
    "\n",
    "    # Return the plot and the file for download\n",
    "    return ax, save_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
